{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "\n",
    "class CustomVOCSegmentation(VOCSegmentation):\n",
    "    def __init__(self, root, image_set=\"train\", download=True, transforms=None):\n",
    "        super().__init__(root=root, image_set=image_set, download=download, transforms=transforms)\n",
    "        self.voc_classes = [\n",
    "            \"background\",\n",
    "            \"aeroplane\",\n",
    "            \"bicycle\",\n",
    "            \"bird\",\n",
    "            \"boat\",\n",
    "            \"bottle\",\n",
    "            \"bus\",\n",
    "            \"car\",\n",
    "            \"cat\",\n",
    "            \"chair\",\n",
    "            \"cow\",\n",
    "            \"diningtable\",\n",
    "            \"dog\",\n",
    "            \"horse\",\n",
    "            \"motorbike\",\n",
    "            \"person\",\n",
    "            \"potted plant\",\n",
    "            \"sheep\",\n",
    "            \"sofa\",\n",
    "            \"train\",\n",
    "            \"tv/monitor\",\n",
    "        ]\n",
    "        self.voc_colormap = [\n",
    "            [0, 0, 0],\n",
    "            [128, 0, 0],\n",
    "            [0, 128, 0],\n",
    "            [128, 128, 0],\n",
    "            [0, 0, 128],\n",
    "            [128, 0, 128],\n",
    "            [0, 128, 128],\n",
    "            [128, 128, 128],\n",
    "            [64, 0, 0],\n",
    "            [192, 0, 0],\n",
    "            [64, 128, 0],\n",
    "            [192, 128, 0],\n",
    "            [64, 0, 128],\n",
    "            [192, 0, 128],\n",
    "            [64, 128, 128],\n",
    "            [192, 128, 128],\n",
    "            [0, 64, 0],\n",
    "            [128, 64, 0],\n",
    "            [0, 192, 0],\n",
    "            [128, 192, 0],\n",
    "            [0, 64, 128],\n",
    "        ]\n",
    "\n",
    "    def _convert_to_segmentation_mask(self,mask):\n",
    "        height, width = mask.shape[:2]\n",
    "        segmentation_mask = np.zeros((height, width, len(self.voc_classes)), dtype=np.float32)\n",
    "        for label_index, label in enumerate(self.voc_colormap):\n",
    "            segmentation_mask[:, :, label_index] = np.all(mask == label, axis=-1).astype(np.float32)\n",
    "        return torch.from_numpy(segmentation_mask.transpose(2,0,1))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input = Image.open(self.images[idx]).convert('RGB')\n",
    "        target = Image.open(self.masks[idx])\n",
    "        \n",
    "        data = (input,target)\n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from transforms import transforms_train\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_dataset(dir_path,name,image_set,transforms):\n",
    "    def sbd(*args, **kwargs):\n",
    "        return torchvision.datasets.SBDataset(*args, mode=\"segmentation\", **kwargs)\n",
    "    paths = {\n",
    "        \"voc2012\": (dir_path, CustomVOCSegmentation, 21),\n",
    "        \"voc_aug\": (dir_path, sbd, 21),\n",
    "    }\n",
    "    p, ds_fn, num_classes = paths[name]\n",
    "    ds = ds_fn(os.path.join(p,name), image_set=image_set,download=True,transforms=transforms)\n",
    "    return ds,num_classes\n",
    "\n",
    "root_dir = '.'\n",
    "data_dir = os.path.join(root_dir,\"dataset\")\n",
    "batch_size = 4\n",
    "train_ds, num_classes = get_dataset(data_dir,\"voc2012\",\"train\",transforms=transforms_train())\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    "    )\n",
    "loader = iter(train_loader)\n",
    "inputs,labels = loader.next()\n",
    "print(inputs.size(),inputs.dtype())\n",
    "print(labels.size(),labels.dtype())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
